# Nginx 简介

**参考文档**

[正向代理与反向代理](https://www.zhihu.com/question/24723688)

[什么是负载均衡 - 博客园](https://www.cnblogs.com/funcquery/p/16009094.html)

---

## 正向代理与反向代理

通俗的来说，正向代理隐藏真实客户端，反向代理隐藏真实服务端。

<img src="https://pic4.zhimg.com/80/480c1c45d2565e2f92fd930d25b73a18_1440w.jpg?source=1940ef5c" title="" alt="" data-align="center">

**正向代理**的过程，它隐藏了真实的客户端请求，服务端不知道真实的客户端是谁，客户端的请求都被代理服务器来处理。比如要访问 youtube，但是不能直接访问，只能先找个翻墙软件，通过翻墙软件才能访问 youtube。翻墙软件就叫做正向代理。

&emsp;

**反向代理**隐藏了真实的服务端，当我们请求某一个网站时，它的背后有成千上万个服务器在运行，具体是哪一个在为我们服务我们并不知道。这样子设计是因为在计算机世界里，由于单个服务器的处理客户端（用户）请求能力有一个极限，当用户的接入请求蜂拥而入时，会造成服务器忙不过来的局面，可以使用多个服务器来共同分担成千上万的用户请求，这些服务器提供相同的服务，对于用户来说，根本感觉不到任何差别。反向代理的实现具体是：

* 需要有一个负载均衡设备来分发用户请求，将用户请求分发到空闲的服务器上。

* 服务器返回自己的服务到负载均衡设备。

* 负载均衡将服务器的服务返回用户。

&emsp;

## 负载均衡

早期的互联网应用，由于用户流量比较小，业务逻辑也比较简单，往往一个单服务器就能满足负载需求。随着现在互联网的流量越来越大，稍微好一点的系统，访问量就非常大了，并且系统功能也越来越复杂，那么单台服务器就算将性能优化得再好，也不能支撑这么大用户量的访问压力了，这个时候就需要使用多台机器，设计高性能的集群来应对。那么，多台服务器是如何去均衡流量、如何组成高性能的集群的呢？此时就需要请出 「负载均衡器」 入场了。负载均衡（Load Balancer）是指把用户访问的流量，通过「负载均衡器」，根据某种转发的策略，均匀的分发到后端多台服务器上，后端的服务器可以独立的响应和处理请求，从而实现分散负载的效果。负载均衡技术提高了系统的服务能力，增强了应用的可用性。

&emsp;

### 原理

系统的扩展可分为纵向（垂直）扩展和横向（水平）扩展。纵向扩展，是从单机的角度通过增加硬件处理能力，比如 CPU 处理能力，内存容量，磁盘等方面，实现服务器处理能力的提升，不能满足大型分布式系统（网站），大流量，高并发，海量数据的问题。因此需要采用横向扩展的方式，通过添加机器来满足大型网站服务的处理能力。比如：一台机器不能满足，则增加两台或者多台机器，共同承担访问压力。这就是典型的集群和负载均衡架构。

**应用集群**：将同一应用部署到多台机器上，组成处理集群，接收负载均衡设备分发的请求，进行处理，并返回相应数据。

**负载均衡设备**：将用户访问的请求，根据负载均衡算法，分发到集群中的一台处理服务（一种把网络请求分散到一个服务器集群中的可用服务器上去的设备）。

&emsp;

 负载均衡的作用包括：

* 解决并发压力，提高应用处理性能（增加吞吐量，加强网络处理能力）；

* 提供故障转移，实现高可用；

* 通过添加或减少服务器数量，提供网站伸缩性（扩展性）；

* 安全防护；（负载均衡设备上做一些过滤，黑白名单等处理）

&emsp;

### 常用的策略

**轮询策略**  
轮询策略其实很好理解，就是当用户请求来了之后，「负载均衡器」将请求轮流的转发到后端不同的业务服务器上。这个策略在DNS方案中用的比较多，无需关注后端服务的状态，只要有请求，就往后端轮流转发，非常的简单、实用。在实际应用中，轮询也会有多种方式。

&emsp;

**负载度策略**  
负载度策略是指当「负载均衡器」往后端转发流量的时候，会先去评估后端每台服务器的负载压力情况，对于压力比较大的后端服务器转发的请求就少一些，对于压力比较小的后端服务器可以多转发一些请求给它。这种方式就充分的结合了后端服务器的运行状态，来动态的分配流量了，比轮询的方式更为科学一些。由于需要通过对许多指标进行计算和对比，判断出哪一台后端服务器的负载压力较大。这种方式带来了效果优势的同时，也增加了「负载均衡器」的实现难度和维护成本。

&emsp;

**最快响应策略**  
响应策略是指，当用户请求过来的时候，「负载均衡器」会优先将请求转发给当前时刻响应最快的后端服务器。也就是说，不管后端服务器负载高不高，也不管配置如何，只要觉得这个服务器在当前时刻能最快的响应用户的请求，那么就优先把请求转发给它，这样的话，对于用户而言，体验也最好。那「负载均衡器」是怎么知道哪一台后端服务在当前时刻响应能力最佳呢？这就需要「负载均衡器」不停的去统计每一台后端服务器对请求的处理速度了，比如一分钟统计一次，生成一个后端服务器处理速度的排行榜。然后「负载均衡器」根据这个排行榜去转发服务。那么这里的问题就是统计的成本了，不停的做这些统计运算本身也会消耗一些性能，同时也会增加「负载均衡器」的实现难度和维护成本。

&emsp;

**哈希策略**  
Hash 策略也比较好理解，就是将请求中的某个信息进行hash计算，然后根据后端服务器台数取模，得到一个值，算出相同值的请求就被转发到同一台后端服务器中。

&emsp;

**IP地址散列**  
通过管理发送方IP和目的地IP地址的散列，将来自同一发送方的分组(或发送至同一目的地的分组)统一转发到相同服务器的算法。当客户端有一系列业务需要处理而必须和一个服务器反复通信时，该算法能够以流(会话)为单位，保证来自相同客户端的通信能够一直在同一服务器中进行处理。

&emsp;

**最少链接策略**

在多个服务器中，与处理连接数(会话数)最少的服务器进行通信的算法。即使在每台服务器处理能力各不相同，每笔业务处理量也不相同的情况下，也能够在一定程度上降低服务器的负载。

&emsp;

## Nginx

Nginx是一款自由的、开源的、高性能的HTTP服务器和反向代理服务器；同时也是一个IMAP、POP3、SMTP 代理服务器；Nginx 可以作为一个 HTTP 服务器进行网站的发布处理，另外 Nginx 可以作为反向代理进行负载均衡的实现。
